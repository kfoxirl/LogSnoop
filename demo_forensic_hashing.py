#!/usr/bin/env python3
"""
Comprehensive HTTP File Hash Analysis Demonstration
Shows full forensic capabilities for file integrity verification
"""

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from logsnoop.plugins.pcap_network import PcapNetworkPlugin

def demonstrate_forensic_capabilities():
    """Demonstrate comprehensive forensic file hash analysis capabilities."""
    
    print("ğŸ•µï¸  HTTP FILE HASH ANALYSIS - DIGITAL FORENSICS CAPABILITIES")
    print("=" * 90)
    
    plugin = PcapNetworkPlugin()
    
    # Test with HTTP2.pcap
    test_file = 'test_data/HTTP2.pcap'
    
    print(f"ğŸ“ Forensic Analysis of: {test_file}")
    result = plugin.parse_binary_file(test_file)
    entries = result['entries']
    print(f"ğŸ“Š Evidence Base: {len(entries)} network packets processed")
    
    print(f"\nğŸ”¬ FORENSIC ANALYSIS SUITE")
    print("=" * 90)
    
    # Run all file-related analyses
    analyses = [
        ('http_file_downloads', 'Standard File Download Detection'),
        ('http_file_hashes', 'Advanced File Hash Fingerprinting'),
        ('http_security', 'Security Threat Assessment'),
        ('http_performance', 'Bandwidth and Transfer Analysis')
    ]
    
    results = {}
    
    for query_name, description in analyses:
        print(f"\n--- ğŸ¯ {description.upper()} ---")
        try:
            result = plugin.query(query_name, entries)
            results[query_name] = result
            
            if query_name == 'http_file_downloads':
                print(f"âœ… Files Detected: {result.get('total_downloads', 0)}")
                print(f"ğŸ“Š Total Size: {result.get('total_download_mb', 0)} MB")
                print(f"ğŸ“ File Types: {list(result.get('downloads_by_type', {}).keys())}")
                
            elif query_name == 'http_file_hashes':
                print(f"ğŸ” Files with Hash Analysis: {result.get('total_downloads_with_hashes', 0)}")
                print(f"ğŸ†” Unique MD5 Fingerprints: {result.get('unique_md5_hashes', 0)}")
                print(f"ğŸ”‘ Unique SHA256 Fingerprints: {result.get('unique_sha256_hashes', 0)}")
                print(f"ğŸ‘¥ Duplicate Detection: {result.get('duplicate_files_detected', 0)} potential duplicates")
                
            elif query_name == 'http_security':
                print(f"ğŸ›¡ï¸  Security Score: {result.get('security_score', 0)}/100")
                print(f"ğŸš¨ Suspicious Patterns: {result.get('suspicious_requests', 0)}")
                print(f"ğŸ” Auth Failures: {result.get('authentication_failures_401', 0)}")
                
            elif query_name == 'http_performance':
                print(f"ğŸ“ˆ Transfer Efficiency: {result.get('avg_response_size', 0):,} bytes avg response")
                print(f"ğŸ“Š Large Files (>1MB): {result.get('large_responses_1mb_plus', 0)}")
                
        except Exception as e:
            print(f"âŒ Analysis Error: {e}")
    
    # Detailed forensic report
    if 'http_file_hashes' in results:
        hash_data = results['http_file_hashes']
        
        print(f"\nğŸ—‚ï¸  DETAILED FORENSIC FILE EVIDENCE")
        print("=" * 90)
        
        files = hash_data.get('file_downloads_with_hashes', [])
        for i, file_evidence in enumerate(files, 1):
            print(f"\nğŸ“‹ EVIDENCE FILE #{i}")
            print(f"  ğŸ• Timestamp: {file_evidence.get('timestamp', 'Unknown')}")
            print(f"  ğŸ“ File Size: {file_evidence.get('size_bytes', 0):,} bytes")
            print(f"  ğŸ·ï¸  MIME Type: {file_evidence.get('content_type', 'Unknown')}")
            print(f"  ğŸ“‚ Classification: {file_evidence.get('file_type', 'Unknown')}")
            print(f"  ğŸ“Š HTTP Status: {file_evidence.get('status_code', 'Unknown')}")
            print(f"  ğŸŒ Network Flow: {file_evidence.get('src_ip', 'Unknown')} â†’ {file_evidence.get('dst_ip', 'Unknown')}")
            print(f"  ğŸ” MD5 Fingerprint: {file_evidence.get('md5_hash', 'N/A')}")
            print(f"  ğŸ”‘ SHA256 Fingerprint: {file_evidence.get('sha256_hash', 'N/A')}")
            print(f"  ğŸ“¦ Packet Size: {file_evidence.get('packet_size', 0):,} bytes")
            
            # Forensic analysis
            size_mb = file_evidence.get('size_mb', 0)
            if size_mb > 10:
                print(f"  ğŸš¨ ALERT: Large file transfer detected ({size_mb} MB)")
            
            content_type = file_evidence.get('content_type', '')
            if 'application/octet-stream' in content_type:
                print(f"  âš ï¸  WARNING: Binary executable content detected")
            elif 'zip' in content_type or 'archive' in content_type:
                print(f"  ğŸ“¦ INFO: Archive file detected - may contain multiple files")
            elif 'image' in content_type:
                print(f"  ğŸ–¼ï¸  INFO: Image file detected")
        
        print(f"\nğŸ”¬ HASH ANALYSIS INTELLIGENCE")
        print("=" * 90)
        
        forensic = hash_data.get('forensic_summary', {})
        hash_analysis = hash_data.get('hash_analysis', {})
        
        print(f"ğŸ“Š Evidence Summary:")
        print(f"  â€¢ Total Files Analyzed: {forensic.get('total_files', 0)}")
        print(f"  â€¢ Unique File Signatures: {forensic.get('unique_file_fingerprints', 0)}")
        print(f"  â€¢ Largest Transfer: {forensic.get('largest_download_mb', 0)} MB")
        print(f"  â€¢ File Categories: {', '.join(forensic.get('file_types_detected', []))}")
        
        print(f"\nğŸ” Hash Collision Analysis:")
        print(f"  â€¢ MD5 Collision Risk: {hash_analysis.get('md5_collision_potential', 0)} files")
        print(f"  â€¢ SHA256 Collision Risk: {hash_analysis.get('sha256_collision_potential', 0)} files")
        print(f"  â€¢ Hash Method: {hash_analysis.get('hash_calculation_method', 'Unknown')}")
        
    print(f"\nğŸ¯ FORENSIC ANALYSIS CAPABILITIES SUMMARY")
    print("=" * 90)
    print("âœ… File Integrity Verification: MD5 and SHA256 hash generation")
    print("âœ… Duplicate File Detection: Identifies identical files by hash")
    print("âœ… File Type Classification: Automatic categorization by content and headers")
    print("âœ… Transfer Timeline Analysis: Chronological file movement tracking")
    print("âœ… Network Flow Mapping: Source/destination IP correlation")
    print("âœ… Content Security Analysis: Suspicious file pattern detection")
    print("âœ… Digital Evidence Chain: Complete forensic metadata preservation")
    print("âœ… Malware Investigation Ready: Hash comparison with threat intelligence")
    
    print(f"\nğŸ’¼ FORENSIC USE CASES:")
    print("ğŸ” Data Exfiltration Investigation: Track unauthorized file transfers")
    print("ğŸ›¡ï¸  Malware Analysis: Hash comparison with known threat signatures")
    print("ğŸ“Š Compliance Auditing: Verify file transfer policies and procedures")
    print("ğŸ•µï¸  Incident Response: Rapid file integrity verification during breaches")
    print("âš–ï¸  Legal Evidence: Generate court-admissible file transfer records")
    print("ğŸ” Data Loss Prevention: Monitor sensitive file movements")
    
    print(f"\nğŸ† LogSnoop HTTP Hash Analysis: Enterprise Digital Forensics Platform")

if __name__ == "__main__":
    demonstrate_forensic_capabilities()